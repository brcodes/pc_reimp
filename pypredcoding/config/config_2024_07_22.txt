## Config file for PCC (r/s) experiments
## Parsed downstream by literal_eval (ast)
## << KEEP EVERYTHING IN THE FORMAT DENOTED BY COMMENTS, OR ERRORS MAY OCCUR >>

## METADATA AND EXPERIMENT
# Keep in format TEXT_YEAR_TWODIGMONTH_DAY
# Will append model and log filenames
# When you want to access a checkpoint later, you need to use this exact name. 
# You can note that you are re-training in the notes below- and note the new date of the retraining.
name="'Experiment_2024_07_24'"
train="True"
evaluate="False"
predict="False"
notes="'A String of any type for note-taking. e.g. Training 2024.07.24 checkpoint ep 70 to epoch 300 on 2024.07.26 '"

## PCC MODEL
# << will automatically make this model if not found in models/ and train="True" above; else ValueError >>
# Can be static or recurrent
model_type="'static'"
# Can be tiled or not
tiled="True"
# Total layers ('0th', ie input does not count. only include hidden plus output)
num_layers="3"
# If 2D array, all tiles associated with a sigle image and a tile's area
# If Int, size of flattened single image
input_size="[16,864]"
# For a 1-layer model, this will be ignored for output_lyr_size
# in a 2-layer model, this will have one number, and the second layer will be output_lyr_size
hidden_lyr_sizes="[32,128]"
# If classif_method None or 'c2', can be any size; 'c1' must have size == number of classes
# For a 1-layer model, must be the single layer size
output_lyr_size ="212"
# C1 or C2, see Rogers/Brown work for clarification; can be None, 'c1', 'c2'
classif_method="'c1'"
# Tanh or linear
activ_func="'linear'"
# Gaussian random or sparse kurtotic (kurtotic approximatable as zeros- Li method)
priors="'kurtotic'"
# Li method, r/U,V (W = Weights) updated together for 30 iters per image: {'rW_niters':30}
# Rogers/Brown proposal #1: r updated for 100 iters per image before U or V update {'r_niters_W':100}
# Rogers/Brown proposal #2. r updated until change in vector < some stop criterion per image, then U or V  {'r_eq_W':0.05}
update_method="{'rW_niters':30}"

## TRAINING DATASET
# << will automatically create this dataset if not found in data/ >>
# Format ds.NAME_NUMIMGS_PREPRO(li_trace212)_IMGX_IMGY_TILED_NUMTILES_TILEX_TILEY_TILEOFFSETX_TILEOFFSETY.pydb
dataset_train=ds.trace212_212_li_trace212_132_84_tl_16_36_24_32_20.pydb

## TRAINING HYPERPARAMETERS
# Stochastic gradient descent is 1, all above is batch gd.
batch_size="1"
# how many exposures to all of the data (shuffled)
epoch_n="300"
# learning rates
k_r="{1:0.05, 2:0.05, 3:0.05, 'o':0.01}"
k_U="{1:0.05, 2:0.05, 3:0.05, 'o':0.01}"
# rPCC only
# k_V="{1:0.05, 2:0.05, 3:0.05}"

# save checkpoints? None, save every ('save_every') Int or every 'fraction' (Float, 1/N) of total epochs
# The only thing that differentiates a 'checkpoint' from a 'model' is abstractly the latter is considered fully trained, while the former is not
# Under this paradigm, models are saved in models/ and checkpoints are saved in models/checkpoints/
save_checkpoint="{'save_every':50}"
# if checkpoints present, load? None, or Int != -1 for checkpoint epoch desired. Int == -1 for latest checkpoint.
load_checkpoint="-1"
# plot loss and accuracy by epoch
plot_train="True"

## EVALUATION DATASET
# << will automatically create this dataset if not found in data/ >>
dataset_eval=ds.trace212_212_li_trace212_132_84_tl_16_36_24_32_20.pydb

## EVALUATION HYPERPARAMETERS
# Plot PE of first image only
plot_eval="'first'"

## PREDICTION DATASET
dataset_pred=ds.trace212_212_li_trace212_132_84_tl_16_36_24_32_20.pydb

## PREDICTION HYPERPARAMETERS
# Plot PE, topmost representation of first image only
plot_pred="'first'"

## Dataset creation or loading




